{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Text and File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a cool thing about this is that we can work with files in a very natural way.  For example, I can import text files such as 'beyonce.txt' and then print the lines by writing the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "count = 0\n",
    "for line in queen_bee:\n",
    "    count += 1\n",
    "    print \"The line number is %d.\" % count\n",
    "    print line\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that yes, the text file is treated as a series of lines. And in terms of reading the lines, that is also straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "for line in queen_bee:\n",
    "    line = line.rstrip() # Remove trailing white space\n",
    "    words = line.split() # Turns the line into a list of words\n",
    "    print words[0]\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can then readily start answering various questions.  Like, what if we want to print out only those lines that contain the word 'fire' in them.  Then what we do is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "for line in queen_bee:\n",
    "    line = line.rstrip() # Remove trailing white space\n",
    "    words = line.split() # Turns the line into a list of words by breaking line up across spaces.\n",
    "    if \"fire\" in words:\n",
    "        print line\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that didn't do anything.  Why not?  Write the code that will actually do something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So maybe we also want to process each line not just into words, but remove punctuation marks. How would you do this for just commas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queen_bee = open('beyonce.txt')\n",
    "\n",
    "for line in queen_bee:\n",
    "    line = line.rstrip() # Remove trailing white space\n",
    "    words = line.split() # Turns the line into a list of words by breaking line up across spaces.\n",
    "    cnt = 0\n",
    "    cuts = []\n",
    "    for word in words:\n",
    "        if \",\" in word:\n",
    "            words[cnt] = word[0:len(word)-1] # Thus, we change the list element, not the word itself.\n",
    "        cnt+=1\n",
    "    if \"fire\" in words:\n",
    "        print line\n",
    "\n",
    "queen_bee.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, your turn.  Write a program that does two things.  First, not only should it remove commas, but it should keep track from which words the commas were removed.  Second, it should determine if a line contains the word \"fire\", and if it does, replace \"fire\" with \"flames\".  Lastly, it should print the modified line.  To do the word replacement easily, use the list command\n",
    "\n",
    "`words.index(\"fire\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now of course, the punctuation is all wacky.  Can you find a way to put the punctuation back where it belongs?  To do this, we need to try and use string concantenation.  So for example if I type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"flames\"+\",\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So using this, and noting that you have kept track of when you removed commas, to put the commas back in the right places, try using string concantenation in just the right places and then use \n",
    "\n",
    "`delimeter = ' '`\n",
    "\n",
    "`print delimeter.join(words)`\n",
    "\n",
    "to transform the list of words back into a line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you can do that, write a program which counts and then removes all punctuation.  Further, your program should count how many times the letter 't' occurs in the document.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build a function whose job it is to provide a histogram of the letters in a given body of text.  Along the way, we need to build helper functions which the main function will call.  But let's get a template of an idea down first.  \n",
    "\n",
    "We want to pass in a filename, say \"juliet.txt\" or \"beyonce.txt\", and then get a plot of the frequency with which different letters appear.  We should return the distribution as a list.\n",
    "\n",
    "But okay, we want to do a frequency analysis of letters.  That means we want to get rid of punctuation.  So we need to develop a helper function which takes a list of words, strips the punctuation while keeping all the letters.  \n",
    "\n",
    "Now note, because we have Shakespeare to analyze, we have to allow that things like apostrophes can come at almost any point in the word.  So be careful.  Your helper function should return a list of words with no punctuation.  You will need to use the string helper function\n",
    "\n",
    "`word.isalnum()`\n",
    "\n",
    "which tests if a string consists only of alpha/numeric characters.  Also, don't forget about good stuff like \n",
    "\n",
    " `word.append(char)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc_remove(words):\n",
    "    ind = 0\n",
    "    for word in words:\n",
    "            # Here is where you need to start introducing code.\n",
    "            if :\n",
    "                wordt = []\n",
    "                for char in word:\n",
    "                    if :\n",
    "                        wordt.append(char)\n",
    "                delimeter = \"\"\n",
    "                words[ind] = delimeter.join(wordt) # Note the absence of a return statement since we rely\n",
    "                                                   # on pass by reference to modify words both within\n",
    "                                                   # the function and then used afterwards in its \n",
    "                                                   # modified form.\n",
    "            ind+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to think about lower and upper case.  So, we would like a helper function which takes a list of words and converts everything to upper case.  Note, you will need to make use of the string helper function\n",
    "\n",
    "`word.upper()`\n",
    "\n",
    "which makes every character in a string uppercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_upper(words):\n",
    "    ind = 0\n",
    "    for word in words:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now the hard part.  We need to build a helper function which is able to take a given string or word, and a list which is keeping track of the frequency of occurences of each letter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letter_cnt(word,freq_d):\n",
    "    for let in word: freq_d[let]+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "    \n",
    "def letter_freq(fname):\n",
    "    fhand = open(fname)\n",
    "    alpha = list(string.uppercase[:26])\n",
    "    freq_d = dict()\n",
    "    for let in alpha: freq_d[let] = 0\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
