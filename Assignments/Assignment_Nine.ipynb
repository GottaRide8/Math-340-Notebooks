{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: 10 pts - Here is a cubic polynomial with three closely spaced real roots:\n",
    "\n",
    "$$\n",
    "p(x) = 816x^3 - 3835x^2 + 6000x - 3125\n",
    "$$\n",
    "\n",
    "* What are the exact roots of p?\n",
    "* Plot $p(x)$ for $1.43\\leq x \\leq 1.71$.  Show the location of the three roots.  \n",
    "* Starting with $x_{0}=1.5$, what does Newton's method do?\n",
    "* Starting with $x_{0}=1$ and $x_{1}=2$, what does the secant method do?\n",
    "* Starting with the interval $[1,2]$, what does bisection do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**: 10 pts - Find the first ten positive values of $x$ such that $x = \\tan(x)$.  Explain your choice of root finding method for doing this, and explain how you are certain that you have found the first ten positive values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**: 10 pts - Suppose that we interpolate over three points, say $x_{j-1}$, $x_{j}$, $x_{j+1}$, with data $f_{j-1}$, $f_{j}$, and $f_{j+1}$, where our nodes are equally spaced so that \n",
    "\n",
    "$$\n",
    "\\delta x = x_{j+1} - x_{j} = x_{j} - x_{j-1}.\n",
    "$$\n",
    "\n",
    "Thus we can write \n",
    "\n",
    "$$\n",
    "x_{j+1} = x_{j} + \\delta x, ~ x_{j-1} = x_{j} - \\delta x,\n",
    "$$\n",
    "\n",
    "As we discussed in class, for an unknown function $f(x)$, we can generate an interpolatory second-order approximation $P_{2}(x)$, $f(x)\\approx P_{2}(x)$, where\n",
    "\n",
    "$$\n",
    "P_{2}(x) = f_{j-1}\\frac{(x-x_{j})(x-x_{j+1})}{(x_{j-1}-x_{j})(x_{j-1}-x_{j+1})} + f_{j}\\frac{(x-x_{j-1})(x-x_{j+1})}{(x_{j}-x_{j-1})(x_{j}-x_{j+1})} + f_{j+1}\\frac{(x-x_{j-1})(x-x_{j})}{(x_{j+1}-x_{j-1})(x_{j+1}-x_{j})}\n",
    "$$\n",
    "\n",
    "Show that \n",
    "\n",
    "* (4pts) $P_{2}(x) = \\frac{1}{2\\delta x^{2}}\\left(f_{j-1}\\tilde{x}(\\tilde{x}-\\delta x) - 2f_{j}(\\tilde{x}-\\delta x)(\\tilde{x}+\\delta x) + f_{j+1}\\tilde{x}(\\tilde{x}+\\delta x)\\right)$, $\\tilde{x} = x-x_{j}$.\n",
    "\n",
    "* (3pts) $P'_{2}(x_{j}) = \\frac{1}{2\\delta x}\\left(f_{j+1} - f_{j-1} \\right)$.  Letting $f'(x_{j})\\approx P'_{2}(x_{j})$ is known as a _centered difference_ approximation to a derivative of a function.\n",
    "\n",
    "* (3pts) $P''_{2}(x_{j}) = \\frac{1}{\\delta x^{2}}\\left(f_{j+1} - 2f_{j} + f_{j-1}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4**: 10 pts \n",
    "* (3 pts) Using $f(x) = \\cos(x)$, determine the accuracy of your centered difference approximations for $f'(x_{j})$ and $f''(x_{j})$ with respect to the magnitude of $\\delta x$.  In other words, if we suppose that \n",
    "$$\n",
    "f'(x_{j}) = \\frac{f_{j+1}-f_{j-1}}{2\\delta x} + C\\delta x^{p},\n",
    "$$\n",
    "then find $p$.  Note, in order to measure the error in our approximations, we look at points $x_{j}\\in[0, 2\\pi]$ where $\\delta x = 2\\pi/N$ so that\n",
    "$$\n",
    "x_{j} = \\frac{2\\pi j}{N}, ~j=0, \\cdots, N.\n",
    "$$\n",
    "We plot the maximum of the absolute value of the error in our approximation over our chosen interval for increasing choices of $N$.\n",
    "\n",
    "* (3 pts) Using $P_{4}(x)$, derive a centered difference approximation for $f'(x_{j})$ using the equally spaced nodes $x_{j-2}$, $x_{j-1}$, $x_{j}$, $x_{j+1}$, $x_{j+2}$, with corresponding node spacing $\\delta x$, and corresponding data $f_{j-2}$, $f_{j-1}$, $f_{j}$, $f_{j+1}$, $f_{j+2}$.  Note, you'll need to first show that \n",
    "\\begin{multline}\n",
    "P_{4}(x) = \\frac{1}{(\\delta x)^{4}}\\left(\\frac{f_{j-2}}{4!}(\\tilde{x}+\\delta x)\\tilde{x}(\\tilde{x}-\\delta x)(\\tilde{x}-2\\delta x) -\\frac{f_{j-1}}{3!}(\\tilde{x}+2\\delta x)\\tilde{x}(\\tilde{x}-\\delta x)(\\tilde{x}-2\\delta x) + \\frac{f_{j}}{4}(\\tilde{x}+2\\delta x)(\\tilde{x}+\\delta x)(\\tilde{x}-\\delta x)(\\tilde{x}-2\\delta x)\\right.\\\\\n",
    "\\left.-\\frac{f_{j+1}}{3!}(\\tilde{x}+2\\delta x)(\\tilde{x}+\\delta x)\\tilde{x}(\\tilde{x}-2\\delta x)+ \\frac{f_{j+2}}{4!}(\\tilde{x}+2\\delta x)(\\tilde{x}+\\delta x)\\tilde{x}(\\tilde{x}-\\delta x)\\right)\n",
    "\\end{multline}\n",
    "where again $\\tilde{x}=x-x_{j}$.  I know this looks nasty, but if you see the underlying pattern, it's not nearly as bad.\n",
    "\n",
    "* (4 pts) Determine the order of accuracy of your five point approximation again using $f(x) = \\cos(x)$ using the same approach you used in the first part of this problem.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
